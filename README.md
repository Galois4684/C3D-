## 基于C3D算法的人体动作识别模型

#### 1. C3D算法简介

论文：https://arxiv.org/abs/1412.0767v4

代码：源代码已上传至个人github仓库：https://github.com/Galois4684/-C3D-

###### 1.1 背景
卷积神经网络（CNN）被广泛应用于计算机视觉中，包括分类、检测、分割等任务。

这些任务一般都是针对图像进行的，使用的是二维卷积（即卷积核的维度为二维）。而对于基于视频分析的问题，2D convolution不能很好得捕获时序上的信息，因此3D卷积就被提出来了。

3D卷积 最早应该是在 《3D convolutional neural networks for human action recognition》 这片论文中被提出并用于行为识别的，而C3D是作为一个通用的网络提出的，论文中将其用于行为识别，场景识别，视频相似度分析等领域。

下图是论文中C3D网络架构：

![20200630232003301](source\20200630232003301.png)

###### 1.2 C3D特点
3D ConvNets比2D ConvNets更适用于时空特征的学习
对于3D ConvNet而言，在所有层使用3×3×3的小卷积核效果最好
通过简单的线性分类器学到的特征名为C3D(Convolutional 3D)，在4个不同的任务和6个基准上表现优秀，在2015年达到SOTA
特征紧凑：在UCF101数据集上得到52.8%的准确率只用了10维（PCA+SVM）
推断快，计算效率非常高，在论文中实验时就有300帧以上的FPS，使用 NVIDIA 1080 GPU 能达到600帧以上
概念简单，易于训练和使用



#### 2. 任务流程

###### 2.1 简介

项目组成：

* 数据处理部分
* 模型搭建部分
* 模型训练部分
* 从RTMP流媒体服务器实时拉流检测

###### 2.2 数据处理

训练数据的原始形式是视频数据，在训练前，需要把视频逐帧转化为图片供后续训练使用。

把视频数据以以下文件树形式放置：
![image-20230612152655740](source\image-20230612152655740.png)

修改class_names.txt内容

![image-20230612152913790](source\image-20230612152913790.png)

将action替换为你的具体的动作名称

运行process.py代码，会生成处理的后的逐帧数据，如下形式：

![image-20230612153229422](source\image-20230612153229422.png)

数据量较大时，请耐心等待。如需调整训练集和验证集的比例，调整test_size参数即可：

![image-20230612164505881](source\image-20230612164505881.png)



###### 2.3 模型搭建

为了加载C3D的预训练权重并且适应任务需求，在模型输出部分fc7之后再增加一个全连接层fc8，将4096个单元映射到你所需要检测的动作的数目个单元。模型具体结构参照上图及代码

在weights文件夹下放置预训练权重文件(https://pan.baidu.com/s/1saNqGBkzZHwZpG-A5RDLVw)，该文件包含模型前7层的权重。

###### 2.4 模型训练

在train.py文件下修改num_classes参数即可开始训练，其余参数可自行调整。

###### 2.4.1实例化Dataset类

在dataset.py文件中，重写的C3DDataset类具有属性root_dir, num_frames，分别表示训练数据的路径及每次模型输入张量的深度（即包含多少帧图形）.按照上述流程root_dir不需要调整，num_frames可根据具体情况修改（论文源代码采用的是num_frames = 16）

![image-20230612164703610](source\image-20230612164703610.png)

###### 2.4.2 训练

开始训练时，冻结前7层，仅调节fc8的权重参数：

![image-20230612164131035](source\image-20230612164131035.png)

![image-20230612164541316](source\image-20230612164541316.png)

训练时，每个epoch都会保存下当前的权重参数至weights文件夹下以及每个epoch的损失函数值至logs文件夹下，进入tensorboard界面根据损失函数的大小选择最佳的权重参数即可。

![image-20230612165707439](source\image-20230612165707439.png)

进入tensorboard界面可能会遇到的问题：

1.

![image-20230612165055161](source\image-20230612165055161.png)

将Anaconda\envs\your_env_name\Scripts路劲配置进环境变量里，用cmd启动

2.

![8932055cad9c4029a1154429a0170c8f](source\8932055cad9c4029a1154429a0170c8f.png)

解决方法：

1. 将 logdir参数 logs 替换为绝对路径

2. tensorboard默认端口6006可能存在占用，尝试  tensorboard --longdir xxxxx(logs的绝对路径)  --port 8080

###### 2.5 RTMP流媒体服务器实时拉流检测

修改inference.py文件下rtmp_url, num_classes，参数至对应值，weight_path修改为训练时表现最好的权重的路径。frequence参数表示从视频流中抽帧的频率，根据具体情况修改。

![image-20230612170459741](source\image-20230612170459741.png)

为了防止延迟持续持续累积的问题，推理部分采用的时多线程方式。主线程持续从视频流里抽帧加入到帧缓冲区队列中，子线程对最新的帧缓冲区队列做实时检测并输出。具体细节见代码，若要对输出部分做修改，请调整process_frames函数

![image-20230612170900853](source\image-20230612170900853.png)

